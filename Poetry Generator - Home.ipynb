{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home\n",
    "\n",
    "A poetry generator about the contradictory ideas of \"home\". Based on A House of Dust by Alison Knowles and James Tenney, using GPT2 generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In \"merriam\", I am using slightly-edited definitions of the word \"home\" from the Merriam-Webster dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "merriam = [\n",
    "'the place where a person lives',\n",
    "'a family living together',\n",
    "'a place where something normally lives',\n",
    "'a place where something naturally is located',\n",
    "'one\\'s place of residence',\n",
    "'the social unit',\n",
    "'a family living together',\n",
    "'a familiar setting',\n",
    "'a congenial environment',\n",
    "'a place of origin',\n",
    "'one s own country',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing a few definitions mostly because they are too long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in merriam:\n",
    "    if len(i) > 31:\n",
    "        merriam.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the place where a person lives',\n",
       " 'a family living together',\n",
       " 'a place where something naturally is located',\n",
       " \"one's place of residence\",\n",
       " 'the social unit',\n",
       " 'a family living together',\n",
       " 'a familiar setting',\n",
       " 'a congenial environment',\n",
       " 'a place of origin',\n",
       " 'one s own country']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merriam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now, let's add GPT2 generated text to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --prefix {sys.prefix} -y -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.9/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am going to generate a list of 30 items, and then pick a few manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    i = generator(\"For me home is\", max_length=13, top_p=.85 )[0]['generated_text']\n",
    "    gpt2text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For me home is what I love most and most deeply,\" she',\n",
       " 'For me home is not only my home but also my childhood,',\n",
       " 'For me home is not a country of rules but a country of',\n",
       " \"For me home is a great place. It's not as if\",\n",
       " \"For me home is where we live, so I can't go\",\n",
       " \"For me home is a place that is my mother's home.\",\n",
       " 'For me home is where I am today. I have been waiting',\n",
       " 'For me home is like the place where the last of all things',\n",
       " \"For me home is more like a big window. It's so\",\n",
       " 'For me home is where my work is done.\\n\\nAnd',\n",
       " 'For me home is a great place to sit and to read.',\n",
       " 'For me home is where you belong.\" The child is very different',\n",
       " 'For me home is just a very small space where I spend most',\n",
       " 'For me home is the most important thing to be alive, and',\n",
       " 'For me home is the house where we always make meals. This',\n",
       " 'For me home is home that is all I want to do.',\n",
       " 'For me home is a house of my own, a room of',\n",
       " 'For me home is a home with my parents, my brothers and',\n",
       " 'For me home is a place of safety. I am not afraid',\n",
       " 'For me home is a place where I can take care of myself',\n",
       " 'For me home is a big thing. I want to be able',\n",
       " 'For me home is a kind of living, where there is no',\n",
       " \"For me home is an environment where I'm not allowed to think\",\n",
       " 'For me home is what I do. The first step is to',\n",
       " 'For me home is the last thing I ever want to live.',\n",
       " 'For me home is always the most exciting part of the day and',\n",
       " 'For me home is a beautiful land. A home that has a',\n",
       " 'For me home is always the best place to go. A small',\n",
       " 'For me home is the feeling of the world. I have always',\n",
       " 'For me home is a place of honor. That means a place']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am pleased with the GPT2 generated text. I previously experimented with different paramenters (beams, top-k, top-p, temperature) and I am using the ones that worked best for my purpose. Same for the prompt \"for me home is\". I experimented with \"Home is\" and the results were underwhelming. Now, let's edit the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "editedgpt2text = [\n",
    " 'what I love most and most deeply',\n",
    " 'not only my home but also my childhood',\n",
    " 'a great place',\n",
    " 'where we live',\n",
    " 'a place that is my mother\\'s home',\n",
    " 'where I am today',\n",
    " 'where my work is done',\n",
    " 'a great place to sit and to read',\n",
    " 'where you belong',\n",
    " 'the most important thing to be alive',\n",
    " 'the house where we always make meals',\n",
    " 'a house of my own',\n",
    " 'a place of safety',\n",
    " 'a place where I can take care of myself',\n",
    " 'always the most exciting part of the day',\n",
    " 'a beautiful land',\n",
    " 'always the best place to go',\n",
    " 'the feeling of the world',\n",
    " 'a place of honor'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now, let's join the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = editedgpt2text + merriam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what I love most and most deeply',\n",
       " 'not only my home but also my childhood',\n",
       " 'a great place',\n",
       " 'where we live',\n",
       " \"a place that is my mother's home\",\n",
       " 'where I am today',\n",
       " 'where my work is done',\n",
       " 'a great place to sit and to read',\n",
       " 'where you belong',\n",
       " 'the most important thing to be alive',\n",
       " 'the house where we always make meals',\n",
       " 'a house of my own',\n",
       " 'a place of safety',\n",
       " 'a place where I can take care of myself',\n",
       " 'always the most exciting part of the day',\n",
       " 'a beautiful land',\n",
       " 'always the best place to go',\n",
       " 'the feeling of the world',\n",
       " 'a place of honor',\n",
       " 'the place where a person lives',\n",
       " 'a family living together',\n",
       " 'a place where something naturally is located',\n",
       " \"one's place of residence\",\n",
       " 'the social unit',\n",
       " 'a family living together',\n",
       " 'a familiar setting',\n",
       " 'a congenial environment',\n",
       " 'a place of origin',\n",
       " 'one s own country']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this is the list of feelings that \"home\" evoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "feelings = [\n",
    "'to visit',\n",
    "'to search for',\n",
    "'to be confused by',\n",
    "'to run away from',\n",
    "'to seek',\n",
    "'to miss',\n",
    "'to stay at',\n",
    "'to long for',\n",
    "'to hate',\n",
    "'to be repulsed by',\n",
    "'to be denied of',\n",
    "'to have',\n",
    "'to love',\n",
    "'to misunderstand',\n",
    "'to be angry at',\n",
    "'to pursue',\n",
    "'to be surprised by'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's put together the stanzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "to misunderstand\n",
      "     a great place to sit and to read\n",
      "          is not \n",
      "           to pursue\n",
      "                 a family living together\n",
      "\n",
      "to be denied of\n",
      "     where I am today\n",
      "          is not \n",
      "           to run away from\n",
      "                 where my work is done\n",
      "\n",
      "to long for\n",
      "     a beautiful land\n",
      "          is not \n",
      "           to visit\n",
      "                 a family living together\n",
      "\n",
      "to stay at\n",
      "     where I am today\n",
      "          is not \n",
      "           to miss\n",
      "                 a place of honor\n",
      "\n",
      "to stay at\n",
      "     a place of safety\n",
      "          is not \n",
      "           to stay at\n",
      "                 always the best place to go\n",
      "\n",
      "to misunderstand\n",
      "     a familiar setting\n",
      "          is not \n",
      "           to hate\n",
      "                 what I love most and most deeply\n",
      "\n",
      "to seek\n",
      "     the house where we always make meals\n",
      "          is not \n",
      "           to miss\n",
      "                 the house where we always make meals\n",
      "\n",
      "to be denied of\n",
      "     a place that is my mother's home\n",
      "          is not \n",
      "           to hate\n",
      "                 where you belong\n",
      "\n",
      "to be confused by\n",
      "     a family living together\n",
      "          is not \n",
      "           to have\n",
      "                 the house where we always make meals\n",
      "\n",
      "to search for\n",
      "     where my work is done\n",
      "          is not \n",
      "           to be repulsed by\n",
      "                 always the most exciting part of the day\n"
     ]
    }
   ],
   "source": [
    "stanza_count = 10\n",
    "for i in range(stanza_count):\n",
    "    print()\n",
    "    print(random.choice(feelings))\n",
    "    print(\"     \" + random.choice(text))\n",
    "    print(\"          is not \" )\n",
    "    print(\"           \" + random.choice(feelings))\n",
    "    print(\"                 \" + random.choice(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
